{"cells":[{"cell_type":"markdown","source":["### Part 1: Retreiving Params from Airflow\nUsing **dbutils.widgets.text**(param, default_value), we can retreive the params pushed by Airflow from within the DatabricksRunNowOperator. <br>\nThe params are indicated by the **notebook_params** parameter."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09c7b0b1-4531-49f9-9a4e-d00b5471fdc4"}}},{"cell_type":"code","source":["dbutils.widgets.text(\"stocks\", \"\")\nportfolio = dbutils.widgets.get(\"stocks\").split(\" \")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f1aa72e-5cfe-4a4a-9d5c-1521644959d0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# https://docs.google.com/document/d/1e9oakyEftdHp4zGz2F0WP-_X7GEzEKYGaPvu1SguuCE/edit\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib as plt\nfrom datetime import datetime\nfrom datetime import date as dt\nfrom datetime import timedelta as td\nimport yfinance as yf # https://pypi.org/project/yfinance/#description\nfrom delta.tables import *"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b9ba527-cd73-4ce0-bb3c-acc02c937461"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["today = dt.today().strftime(\"%m/%d/%Y\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0bc13ec7-dd2e-4a2a-b92b-07ea61e0bcb0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Pull data (API)\nyfinance Python package (https://pypi.org/project/yfinance/) to extract the data from Yahoo Finance.\nData pulled will contain 6 features, including the days’ closing stock price."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38599b1e-9c68-40b1-8ebf-5f4e745a56af"}}},{"cell_type":"code","source":["\"\"\"\nPulling data from Yahoo Finance using the yfinance Python package (https://pypi.org/project/yfinance/).\nCredit: https://github.com/ranaroussi/yfinance\nData pulled will contain 6 features, including the days’ closing stock price.\nThe requested data will be saved into a dictionary.\n\"\"\"\n\ncompany_info = {i: yf.Ticker(i).info for i in portfolio} # API call\nindustry_cap_dict = {i: [company_info[i]['sector'], company_info[i]['marketCap']] for i in portfolio}\n\nindustry_cap_dict"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fce8ee75-bd5c-4524-8908-d7696873afc6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Part 1: Aggregating Market Capitalization (Value) by Industry\nRetreive the industry and market capitalization of each company, followed by aggregating the the market capitalization by industry <br>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08ec5021-83f1-4b45-9aa2-256614786930"}}},{"cell_type":"code","source":["# transform dictionary into dataframe\nindustry_cap_df = pd.DataFrame.from_dict(industry_cap_dict,orient='index',columns=['SECTOR', 'MARKET_CAP'])\n\n# aggregate industries\nindustry_agg = industry_cap_df.groupby(['SECTOR'], as_index=False).sum()\n\n# add column for date\nindustry_agg[\"PERIOD\"] = pd.to_datetime(today)\n\n# add column combining sector and period (For unique ID)\nindustry_agg[\"UNIQUE_ID\"] = industry_agg['SECTOR'] + '_' + str(today)\n\nindustry_agg"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b405b28e-ea89-4432-86e3-8ed8c8dd68a0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Part 2: Delta Table\nTransform the pandas dataframe into a spark dataframe, followed by writing the dataframe onto a Delta Table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa1fac5b-6183-4852-afc4-7e5576851f8d"}}},{"cell_type":"code","source":["# transform pandas dataframe to spark dataframe\nindustry_agg_spdf = spark.createDataFrame(industry_agg)\n\n# save the spark dataframe as a delta table\nindustry_agg_spdf.write.format(\"delta\").mode(\"overwrite\").save(\"/user/hive/warehouse/industry_aggregation_update\")\n\n# load the data from the delta lake using spark (to visualize the data)\nindustry_agg_delta_update = spark.read.format(\"delta\").load(\"/user/hive/warehouse/industry_aggregation_update\")\n \ndisplay(industry_agg_spdf)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"202bc4d6-11e9-4fd1-83f2-e10a09528a39"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Part 3: Upsert\nUpserting the aforementioned Delta Table with the already existing one. The existing table contains prior days' data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f0ef4782-9eae-4e06-b980-297637aee741"}}},{"cell_type":"code","source":["industry_agg_delta = DeltaTable.forPath(spark, \"/user/hive/warehouse/industry_aggregation\")\nindustry_agg_delta_update = DeltaTable.forPath(spark, \"/user/hive/warehouse/industry_aggregation_update\")\n\ndfUpdates = industry_agg_delta_update.toDF()\n\nindustry_agg_delta.alias('data') \\\n  .merge(\n    dfUpdates.alias('updates'),\n    'data.UNIQUE_ID = updates.UNIQUE_ID'\n  ) \\\n  .whenMatchedUpdate(set =\n    {\n      \"SECTOR\": \"updates.SECTOR\",\n      \"MARKET_CAP\": \"updates.MARKET_CAP\",\n      \"PERIOD\": \"updates.PERIOD\",\n      \"UNIQUE_ID\": \"updates.UNIQUE_ID\"\n    }\n  ) \\\n  .whenNotMatchedInsert(values =\n    {\n      \"SECTOR\": \"updates.SECTOR\",\n      \"MARKET_CAP\": \"updates.MARKET_CAP\",\n      \"PERIOD\": \"updates.PERIOD\",\n      \"UNIQUE_ID\": \"updates.UNIQUE_ID\"\n    }\n  ) \\\n  .execute()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b738ccf-52c2-4a41-8e02-4ad006f6e327"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"44904264-72c5-45a3-b227-6cfa74410e16"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Data to be used for notification purposes:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee858d86-59d6-4098-96da-c0b48f2728c4"}}},{"cell_type":"code","source":["current_stock_price = yf.download(portfolio, dt.today(), group_by='Ticker')\ncurrent_stock_price = current_stock_price.stack(level=0).rename_axis(['Date', 'Ticker']).reset_index()\n\ncurrent_stock_price"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff2240f9-881e-44aa-8874-408219375e73"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["previous_stock_price = spark.sql(\"\"\"\n          SELECT * FROM default.financial_info_spdf \n          WHERE Date = (\n              SELECT MAX(Date)\n              FROM default.financial_info_spdf)\"\"\")\n\nprevious_stock_price = previous_stock_price.toPandas()\n\nprevious_stock_price"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b20659de-cbef-4f1c-b305-a946981c6baf"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\nstock_notification = pd.merge(\n    left=previous_stock_price, right=current_stock_price, how='outer', left_on='Ticker', right_on='Ticker')\n\nstock_notification['Percent_Diff'] = round(\n  (stock_notification['Adj Close'] - stock_notification['Adj_Close']) / stock_notification['Adj Close'], 5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72e02e14-5c3c-4e7d-8ab3-8be434b7166d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Adding Financial info to Delta Table\n\ncurrent_stock_price.rename(columns={\"Adj Close\": \"Adj_Close\"}, inplace = True)\ncurrent_stock_price[\"ID\"] = current_stock_price['Ticker'] + \"_\" + current_stock_price['Date'].dt.strftime('%Y-%m-%d')\n\nfinancial_info_spdf_update = spark.createDataFrame(current_stock_price)\nfinancial_info_spdf_update.write.format(\"delta\").mode(\"overwrite\").save(\"/user/hive/warehouse/financial_info_spdf_update\")\n\n\nindustry_agg_delta = DeltaTable.forPath(spark, '/user/hive/warehouse/financial_info_spdf')\nindustry_agg_delta_update = DeltaTable.forPath(spark, \"/user/hive/warehouse/financial_info_spdf_update\")\n\ndfUpdates = industry_agg_delta_update.toDF()\n\nindustry_agg_delta.alias('data') \\\n  .merge(\n    dfUpdates.alias('updates'),\n    'data.ID = updates.ID'\n  ) \\\n  .whenMatchedUpdate(set =\n    {\n      \"Date\": \"updates.Date\",\n      \"Ticker\": \"updates.Ticker\",\n      \"Adj_Close\": \"updates.Adj_Close\",\n      \"Close\": \"updates.Close\",\n      \"High\": \"updates.High\",\n      \"Low\": \"updates.Low\",\n      \"Open\": \"updates.Open\",\n      \"Volume\": \"updates.Volume\",\n      \"ID\": \"updates.ID\"\n    }\n  ) \\\n  .whenNotMatchedInsert(values =\n    {\n      \"Date\": \"updates.Date\",\n      \"Ticker\": \"updates.Ticker\",\n      \"Adj_Close\": \"updates.Adj_Close\",\n      \"Close\": \"updates.Close\",\n      \"High\": \"updates.High\",\n      \"Low\": \"updates.Low\",\n      \"Open\": \"updates.Open\",\n      \"Volume\": \"updates.Volume\",\n      \"ID\": \"updates.ID\"\n    }\n  ) \\\n  .execute()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66062c60-3842-44e7-95cf-c232612e8aeb"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["big_movers = stock_notification[abs(stock_notification['Percent_Diff']) > 0.05][['Ticker','Percent_Diff']].values.tolist()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7230b3c3-116f-4ff7-81c3-ef41eccd81fd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dbutils.notebook.exit(big_movers)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f41751a-e9f3-438b-bea0-721811e864b6"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"dag-workshop","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{"stocks":{"nuid":"d8baf4bb-ef4c-44fa-bd96-2ca793e30f91","currentValue":"","widgetInfo":{"widgetType":"text","name":"stocks","defaultValue":"","label":null,"options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":3755975967354530}},"nbformat":4,"nbformat_minor":0}
